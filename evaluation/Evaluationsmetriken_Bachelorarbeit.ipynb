{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install rouge-score"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KetNCsTreeec",
        "outputId": "d60b6895-5103-4593-e629-2b05fb7492fe"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting rouge-score\n",
            "  Downloading rouge_score-0.1.2.tar.gz (17 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: absl-py in /usr/local/lib/python3.10/dist-packages (from rouge-score) (1.4.0)\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.10/dist-packages (from rouge-score) (3.9.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from rouge-score) (1.26.4)\n",
            "Requirement already satisfied: six>=1.14.0 in /usr/local/lib/python3.10/dist-packages (from rouge-score) (1.17.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from nltk->rouge-score) (8.1.7)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from nltk->rouge-score) (1.4.2)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.10/dist-packages (from nltk->rouge-score) (2024.11.6)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from nltk->rouge-score) (4.67.1)\n",
            "Building wheels for collected packages: rouge-score\n",
            "  Building wheel for rouge-score (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for rouge-score: filename=rouge_score-0.1.2-py3-none-any.whl size=24935 sha256=ac7a0aec5434d01bf85976778e73e8c2c41a44f590539ec45eb2f295c00ba166\n",
            "  Stored in directory: /root/.cache/pip/wheels/5f/dd/89/461065a73be61a532ff8599a28e9beef17985c9e9c31e541b4\n",
            "Successfully built rouge-score\n",
            "Installing collected packages: rouge-score\n",
            "Successfully installed rouge-score-0.1.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install nltk\n",
        "import nltk\n",
        "nltk.download('punkt_tab')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A9RNnO9qhA-w",
        "outputId": "61c7bb1f-50be-4d21-86bd-6ee96497dc58"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: nltk in /usr/local/lib/python3.10/dist-packages (3.9.1)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from nltk) (8.1.7)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from nltk) (1.4.2)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.10/dist-packages (from nltk) (2024.11.6)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from nltk) (4.67.1)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt_tab to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt_tab.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from rouge_score import rouge_scorer\n",
        "from nltk.translate import meteor_score\n",
        "import nltk\n",
        "from typing import List, Dict, Tuple"
      ],
      "metadata": {
        "id": "zYciGuTgeS1U"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "1H8Sxyonc9ax"
      },
      "outputs": [],
      "source": [
        "class SummaryEvaluator:\n",
        "    def __init__(self):\n",
        "        \"\"\"Initialisieren Sie den Evaluator mit den notwendigen NLTK-Downloads\"\"\"\n",
        "        # Ensure required NLTK data is available\n",
        "        try:\n",
        "            nltk.data.find('wordnet')\n",
        "        except LookupError:\n",
        "            nltk.download('wordnet')\n",
        "\n",
        "        # Initialize ROUGE scorer\n",
        "        self.rouge_scorer = rouge_scorer.RougeScorer(\n",
        "            ['rouge1', 'rouge2', 'rougeL'],\n",
        "            use_stemmer=True\n",
        "        )\n",
        "\n",
        "    def calculate_rouge_scores(self,\n",
        "                             candidate_summary: str,\n",
        "                             reference_summaries: List[str]) -> Dict[str, float]:\n",
        "        \"\"\"\n",
        "        Berechnet ROUGE-Scores f√ºr eine Kandidatenzusammenfassung anhand mehrerer Referenzen.\n",
        "\n",
        "        Args:\n",
        "            candidate_summary: Die zu bewertende Zusammenfassung\n",
        "            reference_summaries: Liste der Referenzzusammenfassungen\n",
        "\n",
        "        R√ºckgabe:\n",
        "            W√∂rterbuch mit ROUGE-1-, ROUGE-2- und ROUGE-L-Bewertungen\n",
        "        \"\"\"\n",
        "        rouge1_scores = []\n",
        "        rouge2_scores = []\n",
        "        rougeL_scores = []\n",
        "\n",
        "        for reference in reference_summaries:\n",
        "            scores = self.rouge_scorer.score(reference, candidate_summary)\n",
        "\n",
        "            rouge1_scores.append(scores['rouge1'].fmeasure)\n",
        "            rouge2_scores.append(scores['rouge2'].fmeasure)\n",
        "            rougeL_scores.append(scores['rougeL'].fmeasure)\n",
        "\n",
        "        return {\n",
        "            'rouge1': max(rouge1_scores),\n",
        "            'rouge2': max(rouge2_scores),\n",
        "            'rougeL': max(rougeL_scores)\n",
        "        }\n",
        "\n",
        "    def calculate_meteor_score(self,\n",
        "                             candidate_summary: str,\n",
        "                             reference_summaries: List[str]) -> float:\n",
        "        \"\"\"\n",
        "        Berechnet den METEOR-Score f√ºr eine Kandidatenzusammenfassung anhand mehrerer Referenzen.\n",
        "\n",
        "        Args:\n",
        "            candidate_summary: Die zu bewertende Zusammenfassung\n",
        "            reference_summaries: Liste der Referenzzusammenfassungen\n",
        "\n",
        "        R√ºckgabe:\n",
        "            Maximale METEOR-Punktzahl √ºber alle Referenzen\n",
        "        \"\"\"\n",
        "        candidate_tokens = nltk.word_tokenize(candidate_summary.lower())\n",
        "        meteor_scores = []\n",
        "\n",
        "        for reference in reference_summaries:\n",
        "            reference_tokens = nltk.word_tokenize(reference.lower())\n",
        "            score = meteor_score.meteor_score([reference_tokens], candidate_tokens)\n",
        "            meteor_scores.append(score)\n",
        "\n",
        "        return max(meteor_scores)\n",
        "\n",
        "    def evaluate_summaries(self,\n",
        "                         chatgpt_summary: str,\n",
        "                         system_summary: str,\n",
        "                         references: List[str]) -> Tuple[pd.DataFrame, Dict]:\n",
        "        \"\"\"\n",
        "        Bewerten Sie beide Zusammenfassungen anhand der ROUGE- und METEOR-Metriken.\n",
        "\n",
        "        Args:\n",
        "            chatgpt_summary: Von ChatGPT erzeugte Zusammenfassung\n",
        "            system_summary: Vom System erzeugte Zusammenfassung\n",
        "            references: Liste der Referenzzusammenfassungen\n",
        "\n",
        "        R√ºckgabe:\n",
        "            Tupel enth√§lt:\n",
        "            - DataFrame mit detaillierten ROUGE-Bewertungen\n",
        "            - W√∂rterbuch mit METEOR-Bewertungen\n",
        "        \"\"\"\n",
        "        # Calculate ROUGE scores\n",
        "        chatgpt_rouge = self.calculate_rouge_scores(chatgpt_summary, references)\n",
        "        system_rouge = self.calculate_rouge_scores(system_summary, references)\n",
        "\n",
        "        # Calculate METEOR scores\n",
        "        chatgpt_meteor = self.calculate_meteor_score(chatgpt_summary, references)\n",
        "        system_meteor = self.calculate_meteor_score(system_summary, references)\n",
        "\n",
        "        # Create ROUGE comparison DataFrame\n",
        "        rouge_results = pd.DataFrame({\n",
        "            'Metric': ['ROUGE-1', 'ROUGE-2', 'ROUGE-L'],\n",
        "            'ChatGPT': [\n",
        "                chatgpt_rouge['rouge1'],\n",
        "                chatgpt_rouge['rouge2'],\n",
        "                chatgpt_rouge['rougeL']\n",
        "            ],\n",
        "            'Your System': [\n",
        "                system_rouge['rouge1'],\n",
        "                system_rouge['rouge2'],\n",
        "                system_rouge['rougeL']\n",
        "            ]\n",
        "        })\n",
        "\n",
        "        # Create METEOR results dictionary\n",
        "        meteor_results = {\n",
        "            'ChatGPT METEOR': chatgpt_meteor,\n",
        "            'System METEOR': system_meteor\n",
        "        }\n",
        "\n",
        "        return rouge_results, meteor_results\n",
        "\n",
        "def save_results(rouge_df: pd.DataFrame,\n",
        "                meteor_dict: Dict,\n",
        "                output_file: str = 'evaluation_results.txt'):\n",
        "    \"\"\"\n",
        "    Speichern der Auswertungsergebnisse in einer Datei.\n",
        "\n",
        "    Args:\n",
        "        rouge_df: DataFrame mit ROUGE-Bewertungen\n",
        "        meteor_dict: W√∂rterbuch mit METEOR-Bewertungen\n",
        "        ausgabe_datei: Pfad zur Ausgabedatei\n",
        "    \"\"\"\n",
        "    with open(output_file, 'w', encoding='utf-8') as f:\n",
        "        f.write(\"=== ROUGE Scores ===\\n\")\n",
        "        f.write(rouge_df.to_string())\n",
        "        f.write(\"\\n\\n=== METEOR Scores ===\\n\")\n",
        "        for system, score in meteor_dict.items():\n",
        "            f.write(f\"{system}: {score:.4f}\\n\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Testfall \"Nur Bild\"\n",
        "if __name__ == \"__main__\":\n",
        "    references = [\n",
        "        \"Ein ber√ºhrender Moment m√ºtterlicher Freude zeigt sich, als eine Frau ihr l√§chelndes Baby in die Luft hebt.\",\n",
        "        \"Eine Mutter hebt freudig ihr lachendes Baby in die Luft.\",\n",
        "        \"Das Baby tr√§gt eine wei√üe Windel und streckt sich spielerisch, w√§hrend die Mutter es √ºber sich h√§lt und anl√§chelt\"\n",
        "    ]\n",
        "\n",
        "    chatgpt_summary = \"Eine l√§chelnde Frau h√§lt ein fr√∂hliches Baby in einer wei√üen Windel hoch in die Luft.\"\n",
        "    system_summary = \"eine Frau, die ein Baby in die Luft h√§lt.\"\n",
        "\n",
        "    # Initialisiere evaluator\n",
        "    evaluator = SummaryEvaluator()\n",
        "\n",
        "    # Berechne scores\n",
        "    rouge_results, meteor_results = evaluator.evaluate_summaries(\n",
        "        chatgpt_summary,\n",
        "        system_summary,\n",
        "        references\n",
        "    )\n",
        "\n",
        "    # Zeig die Ergebnisse\n",
        "    print(\"\\nROUGE Score Comparison:\")\n",
        "    print(rouge_results.to_string(index=False))\n",
        "    print(\"\\nMETEOR Score Comparison:\")\n",
        "    for system, score in meteor_results.items():\n",
        "        print(f\"{system}: {score:.4f}\")\n",
        "\n",
        "    # Speichere die Ergebnisse in einer Datei\n",
        "    save_results(rouge_results, meteor_results, 'evaluation_nur_Bild.txt')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8upqjdl_djY8",
        "outputId": "537ff774-3bfb-4152-a29d-91365060f539"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "ROUGE Score Comparison:\n",
            " Metric  ChatGPT  Your System\n",
            "ROUGE-1 0.461538     0.500000\n",
            "ROUGE-2 0.222222     0.333333\n",
            "ROUGE-L 0.358974     0.500000\n",
            "\n",
            "METEOR Score Comparison:\n",
            "ChatGPT METEOR: 0.4891\n",
            "System METEOR: 0.5114\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Testfall \"Nur Text\"\n",
        "if __name__ == \"__main__\":\n",
        "    references = [\n",
        "        \"Die Folie beschreibt die zunehmenden Herausforderungen in der Softwaretechnik, wie steigende Komplexit√§t, l√§ngere Lebensdauer und wachsende Anforderungen an Anwendungen. Au√üerdem wird betont, dass die Softwareentwicklung ein zentraler Bestandteil der Systementwicklung ist und die Pflege von Altsystemen immer wichtiger wird.\",\n",
        "        \"Es wird erl√§utert, warum Softwaretechnik wichtig ist, mit Fokus auf die wachsende Komplexit√§t von Programmen und die zunehmende Bedeutung der Softwareentwicklung. Die Pflege von Altsystemen und die l√§ngere Lebensdauer von Software stellen weitere Herausforderungen dar.\",\n",
        "        \"Die Folie thematisiert die Versch√§rfung von Problemen in der Softwaretechnik, einschlie√ülich zunehmender Komplexit√§t, l√§ngerer Lebenszyklen und wachsender Anforderungen. Entwickler widmen sich zunehmend der Pflege bestehender Altsysteme.\"\n",
        "    ]\n",
        "\n",
        "    chatgpt_summary = \"Die Komplexit√§t von Programmen, deren Umfang und Lebensdauer nehmen st√§ndig zu, w√§hrend neue Anwendungen f√ºr den Rechnereinsatz erschlossen werden. Softwareentwicklung ist ein wesentlicher Bestandteil der Systementwicklung, und immer mehr Entwickler sind mit der Pflege von Altsystemen besch√§ftigt. Dies f√ºhrt zu einer Versch√§rfung der Probleme in der Softwareentwicklung.\"\n",
        "    system_summary = \"Komplexit√§t von Programmen nimmt st√§ndig zu Umfang und Lebensdauer nehmen. Neue Anwendungen werden f√ºr den Rechnereinsatz erschlossen. Softwareentwicklung ist ein integraler Bestandteil der Systementwickler.\"\n",
        "\n",
        "    evaluator = SummaryEvaluator()\n",
        "\n",
        "    rouge_results, meteor_results = evaluator.evaluate_summaries(\n",
        "        chatgpt_summary,\n",
        "        system_summary,\n",
        "        references\n",
        "    )\n",
        "\n",
        "    print(\"\\nROUGE Score Comparison:\")\n",
        "    print(rouge_results.to_string(index=False))\n",
        "    print(\"\\nMETEOR Score Comparison:\")\n",
        "    for system, score in meteor_results.items():\n",
        "        print(f\"{system}: {score:.4f}\")\n",
        "\n",
        "    save_results(rouge_results, meteor_results, 'evaluation_nur_Text.txt')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E4Iyb42O98pM",
        "outputId": "fb552124-5bea-4ad7-f5ad-48c7fb22ed98"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "ROUGE Score Comparison:\n",
            " Metric  ChatGPT  Your System\n",
            "ROUGE-1 0.416667     0.318841\n",
            "ROUGE-2 0.133333     0.095238\n",
            "ROUGE-L 0.291667     0.231884\n",
            "\n",
            "METEOR Score Comparison:\n",
            "ChatGPT METEOR: 0.3287\n",
            "System METEOR: 0.1744\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Testfall: Bild und Text\n",
        "if __name__ == \"__main__\":\n",
        "    references = [\n",
        "        \"Die Folie erkl√§rt das Wasserfallmodell als ein lineares Entwicklungsmodell, bei dem Produkte wie in einem Wasserfall von einer Phase zur n√§chsten √ºbergehen. Das Bild eines Wasserfalls verdeutlicht die schrittweise Abfolge, w√§hrend die Text die Urspr√ºnge und Weiterentwicklungen des Modells erl√§utert.\",\n",
        "        \"Das Wasserfallmodell wird als erstes umfassendes Modell der Softwaretechnik beschrieben, basierend auf dem stagewise model von Benington (1956). Das Bild eines Wasserfalls symbolisiert die lineare Struktur, bei der jede Phase abgeschlossen sein muss, bevor die n√§chste beginnt.\",\n",
        "        \"Die Folie stellt das Wasserfallmodell als ein stufenweises Entwicklungsmodell vor, inspiriert vom nat√ºrlichen Ablauf eines Wasserfalls, wie im Bild dargestellt. Urspr√ºnge und Weiterentwicklungen durch Benington, Royce und Boehm werden ebenfalls genannt.\"\n",
        "    ]\n",
        "\n",
        "    chatgpt_summary = \"Das Wasserfallmodell beschreibt einen linearen Entwicklungsprozess, bei dem die Ergebnisse einer Phase wie bei einem Wasserfall in die n√§chste √ºbergehen. Es ist eines der ersten umfassenden Modelle im Software Engineering, basiert auf dem stagewise model von Benington (1956) und wurde durch Royce und Boehm weiterentwickelt. Das Bild eines Wasserfalls verdeutlicht die sequentielle Natur des Prozesses.\"\n",
        "    system_summary = \"HS Bremen, FK4, Softwaretechnik, ISS & ATMECH, WiSe 23/24, Prof. Dr. -Ing. J. Matevska 11 Wasserfallmodell. Basiert auf dem stagewise model von Benington [1956] Weiterentwicklung u. a. durch Royce [1970 & 1987] und Boehm [1981].Das Bild zeigt ein kleiner Wasserfall mitten in einem Wald.\"\n",
        "\n",
        "    evaluator = SummaryEvaluator()\n",
        "\n",
        "    rouge_results, meteor_results = evaluator.evaluate_summaries(\n",
        "        chatgpt_summary,\n",
        "        system_summary,\n",
        "        references\n",
        "    )\n",
        "\n",
        "    print(\"\\nROUGE Score Comparison:\")\n",
        "    print(rouge_results.to_string(index=False))\n",
        "    print(\"\\nMETEOR Score Comparison:\")\n",
        "    for system, score in meteor_results.items():\n",
        "        print(f\"{system}: {score:.4f}\")\n",
        "\n",
        "    save_results(rouge_results, meteor_results, 'evaluation_Bild_und_Text.txt')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Tf4hqIEZNIBw",
        "outputId": "8c4ad98d-8d8d-429a-a767-7cc9d539df2a"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "ROUGE Score Comparison:\n",
            " Metric  ChatGPT  Your System\n",
            "ROUGE-1 0.495050     0.317073\n",
            "ROUGE-2 0.260870     0.175000\n",
            "ROUGE-L 0.319149     0.292683\n",
            "\n",
            "METEOR Score Comparison:\n",
            "ChatGPT METEOR: 0.5322\n",
            "System METEOR: 0.3079\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Testfall: komplexe Bilder\n",
        "if __name__ == \"__main__\":\n",
        "    references = [\n",
        "        \"W√§hrend √Ñnderungen in der Anforderungsdefinition kosteng√ºnstig sind (1x), steigen sie in der Entwicklung (1,5-6x) und explodieren in der Wartung (60-100x).\",\n",
        "        \"Eine gr√ºndliche Anforderungsanalyse minimiert Kostensteigerungen. √Ñnderungen sind in der fr√ºhen Phase kosteng√ºnstig (1x), aber w√§hrend der Wartung k√∂nnen sie bis zu 100-mal teurer werden\",\n",
        "        \"Anforderungen fr√ºhzeitig zu definieren, ist essenziell, da die Kosten f√ºr √Ñnderungen im Entwicklungsprozess exponentiell steigen. W√§hrend sie in der Anforderungsdefinition minimal sind, steigen sie in der Entwicklung um das 1,5- bis 6-fache und in der Wartung um das 60- bis 100-fache\"\n",
        "    ]\n",
        "\n",
        "    chatgpt_summary = \"Die Folie zeigt, warum Anforderungs-Engineering wichtig ist, anhand der steigenden Kosten von √Ñnderungen im Entwicklungsprozess. √Ñnderungen w√§hrend der Anforderungsdefinition kosten am wenigsten (1x), w√§hrend sie in der Entwicklung (1,5‚Äì6x) und besonders in der Wartung (60‚Äì100x) exponentiell teurer werden.\"\n",
        "    system_summary = \"HS Bremen, FK4, TI, Softwaretechnik 2, SoSe 2023, Prof. -Ing. J. Matevska 16 Warum ist Anforderungs-Engineering notwendig.Das Bild zeigt ein Balkendiagramm, das den Prozentsatz der Anzahl der diagnostizierten Personen zeigt.\"\n",
        "\n",
        "    evaluator = SummaryEvaluator()\n",
        "\n",
        "    rouge_results, meteor_results = evaluator.evaluate_summaries(\n",
        "        chatgpt_summary,\n",
        "        system_summary,\n",
        "        references\n",
        "    )\n",
        "\n",
        "    print(\"\\nROUGE Score Comparison:\")\n",
        "    print(rouge_results.to_string(index=False))\n",
        "    print(\"\\nMETEOR Score Comparison:\")\n",
        "    for system, score in meteor_results.items():\n",
        "        print(f\"{system}: {score:.4f}\")\n",
        "\n",
        "    save_results(rouge_results, meteor_results, 'evaluation_komplexe_Bilder.txt')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NkmKLyLDQc_h",
        "outputId": "a4d291ee-eb1b-44ad-e733-9ab1c895a4a7"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "ROUGE Score Comparison:\n",
            " Metric  ChatGPT  Your System\n",
            "ROUGE-1 0.550725     0.126582\n",
            "ROUGE-2 0.388060     0.000000\n",
            "ROUGE-L 0.521739     0.096774\n",
            "\n",
            "METEOR Score Comparison:\n",
            "ChatGPT METEOR: 0.6702\n",
            "System METEOR: 0.0903\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Testfall: Folie mit mathematischen Formeln\n",
        "if __name__ == \"__main__\":\n",
        "    references = [\"Der magnetische Fluss folgt einer sinusf√∂rmigen Funktion, die durch Œ¶=Œ¶maxcos(ùúîùë°) beschrieben wird. Laut Induktionsgesetz induziert eine rotierende Spule in einem Magnetfeld eine sinusf√∂rmige Wechselspannung ùë¢(ùë°)=√ªsin(ùúîùë°), wobei √ª=ùëÅùúîŒ¶max. Die Frequenz f ist der Kehrwert der Periodendauer T, und die Kreisfrequenz œâ ist 2ùúãùëì.\",\n",
        "        \"Eine Spule, die in einem homogenen Magnetfeld gedreht wird, erzeugt eine sinusf√∂rmige Wechselspannung. Der Zusammenhang zwischen Frequenz (f), Periodendauer (T) und Kreisfrequenz (œâ) wird durch ùúî=2ùúãùëì und ùëá=1/ùëì beschrieben. Der magnetische Fluss ver√§ndert sich sinusf√∂rmig mit der Zeit.\",\n",
        "        \"Der magnetische Fluss Œ¶ und die induzierte Spannung ùë¢(ùë°)sind zeitabh√§ngig und folgen sinusf√∂rmigen Gesetzm√§√üigkeiten. Die Kreisfrequenz œâ und die Frequenz f beschreiben die zeitliche Ver√§nderung der Spannung, wobei ùëá=1/f die Periodendauer angibt. Die Induktion basiert auf der Rotation der Spule im Magnetfeld.\"\n",
        "    ]\n",
        "    chatgpt_summary = \"Die Folie erkl√§rt, dass der magnetische Fluss in einer Spule eine sinusf√∂rmige Spannung induziert, wenn die Spule in einem homogenen Magnetfeld rotiert. Die Spannung h√§ngt von der Windungszahl N, der Winkelgeschwindigkeit œâ, und der maximalen Flussdichte Œ¶max ab, mit einer Periodendauer T, die in Sekunden gemessen wird.\"\n",
        "    system_summary = \"F√ºr den magnetischen Fluss ergibt sich somit Œ¶max cosœâ. Die Zeit f√ºr einen vollen Umlauf wird Periodendauer genannt. Die Einheit ist die Sekunde.\"\n",
        "\n",
        "    evaluator = SummaryEvaluator()\n",
        "\n",
        "    rouge_results, meteor_results = evaluator.evaluate_summaries(\n",
        "        chatgpt_summary,\n",
        "        system_summary,\n",
        "        references\n",
        "    )\n",
        "\n",
        "    print(\"\\nROUGE Score Comparison:\")\n",
        "    print(rouge_results.to_string(index=False))\n",
        "    print(\"\\nMETEOR Score Comparison:\")\n",
        "    for system, score in meteor_results.items():\n",
        "        print(f\"{system}: {score:.4f}\")\n",
        "\n",
        "    save_results(rouge_results, meteor_results, 'evaluation_Folie_mit_mathFormeln.txt')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WkJX1Zlt90j4",
        "outputId": "8d686142-b836-439e-954d-96427eca052d"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "ROUGE Score Comparison:\n",
            " Metric  ChatGPT  Your System\n",
            "ROUGE-1 0.478261     0.264706\n",
            "ROUGE-2 0.206897     0.000000\n",
            "ROUGE-L 0.347826     0.205882\n",
            "\n",
            "METEOR Score Comparison:\n",
            "ChatGPT METEOR: 0.3573\n",
            "System METEOR: 0.1160\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n"
          ]
        }
      ]
    }
  ]
}