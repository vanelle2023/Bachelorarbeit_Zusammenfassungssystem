{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install rouge-score"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KetNCsTreeec",
        "outputId": "d60b6895-5103-4593-e629-2b05fb7492fe"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting rouge-score\n",
            "  Downloading rouge_score-0.1.2.tar.gz (17 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: absl-py in /usr/local/lib/python3.10/dist-packages (from rouge-score) (1.4.0)\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.10/dist-packages (from rouge-score) (3.9.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from rouge-score) (1.26.4)\n",
            "Requirement already satisfied: six>=1.14.0 in /usr/local/lib/python3.10/dist-packages (from rouge-score) (1.17.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from nltk->rouge-score) (8.1.7)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from nltk->rouge-score) (1.4.2)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.10/dist-packages (from nltk->rouge-score) (2024.11.6)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from nltk->rouge-score) (4.67.1)\n",
            "Building wheels for collected packages: rouge-score\n",
            "  Building wheel for rouge-score (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for rouge-score: filename=rouge_score-0.1.2-py3-none-any.whl size=24935 sha256=ac7a0aec5434d01bf85976778e73e8c2c41a44f590539ec45eb2f295c00ba166\n",
            "  Stored in directory: /root/.cache/pip/wheels/5f/dd/89/461065a73be61a532ff8599a28e9beef17985c9e9c31e541b4\n",
            "Successfully built rouge-score\n",
            "Installing collected packages: rouge-score\n",
            "Successfully installed rouge-score-0.1.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install nltk\n",
        "import nltk\n",
        "nltk.download('punkt_tab')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A9RNnO9qhA-w",
        "outputId": "61c7bb1f-50be-4d21-86bd-6ee96497dc58"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: nltk in /usr/local/lib/python3.10/dist-packages (3.9.1)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from nltk) (8.1.7)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from nltk) (1.4.2)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.10/dist-packages (from nltk) (2024.11.6)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from nltk) (4.67.1)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt_tab to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt_tab.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from rouge_score import rouge_scorer\n",
        "from nltk.translate import meteor_score\n",
        "import nltk\n",
        "from typing import List, Dict, Tuple"
      ],
      "metadata": {
        "id": "zYciGuTgeS1U"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "1H8Sxyonc9ax"
      },
      "outputs": [],
      "source": [
        "class SummaryEvaluator:\n",
        "    def __init__(self):\n",
        "        \"\"\"Initialisieren Sie den Evaluator mit den notwendigen NLTK-Downloads\"\"\"\n",
        "        # Ensure required NLTK data is available\n",
        "        try:\n",
        "            nltk.data.find('wordnet')\n",
        "        except LookupError:\n",
        "            nltk.download('wordnet')\n",
        "\n",
        "        # Initialize ROUGE scorer\n",
        "        self.rouge_scorer = rouge_scorer.RougeScorer(\n",
        "            ['rouge1', 'rouge2', 'rougeL'],\n",
        "            use_stemmer=True\n",
        "        )\n",
        "\n",
        "    def calculate_rouge_scores(self,\n",
        "                             candidate_summary: str,\n",
        "                             reference_summaries: List[str]) -> Dict[str, float]:\n",
        "        \"\"\"\n",
        "        Berechnet ROUGE-Scores für eine Kandidatenzusammenfassung anhand mehrerer Referenzen.\n",
        "\n",
        "        Args:\n",
        "            candidate_summary: Die zu bewertende Zusammenfassung\n",
        "            reference_summaries: Liste der Referenzzusammenfassungen\n",
        "\n",
        "        Rückgabe:\n",
        "            Wörterbuch mit ROUGE-1-, ROUGE-2- und ROUGE-L-Bewertungen\n",
        "        \"\"\"\n",
        "        rouge1_scores = []\n",
        "        rouge2_scores = []\n",
        "        rougeL_scores = []\n",
        "\n",
        "        for reference in reference_summaries:\n",
        "            scores = self.rouge_scorer.score(reference, candidate_summary)\n",
        "\n",
        "            rouge1_scores.append(scores['rouge1'].fmeasure)\n",
        "            rouge2_scores.append(scores['rouge2'].fmeasure)\n",
        "            rougeL_scores.append(scores['rougeL'].fmeasure)\n",
        "\n",
        "        return {\n",
        "            'rouge1': max(rouge1_scores),\n",
        "            'rouge2': max(rouge2_scores),\n",
        "            'rougeL': max(rougeL_scores)\n",
        "        }\n",
        "\n",
        "    def calculate_meteor_score(self,\n",
        "                             candidate_summary: str,\n",
        "                             reference_summaries: List[str]) -> float:\n",
        "        \"\"\"\n",
        "        Berechnet den METEOR-Score für eine Kandidatenzusammenfassung anhand mehrerer Referenzen.\n",
        "\n",
        "        Args:\n",
        "            candidate_summary: Die zu bewertende Zusammenfassung\n",
        "            reference_summaries: Liste der Referenzzusammenfassungen\n",
        "\n",
        "        Rückgabe:\n",
        "            Maximale METEOR-Punktzahl über alle Referenzen\n",
        "        \"\"\"\n",
        "        candidate_tokens = nltk.word_tokenize(candidate_summary.lower())\n",
        "        meteor_scores = []\n",
        "\n",
        "        for reference in reference_summaries:\n",
        "            reference_tokens = nltk.word_tokenize(reference.lower())\n",
        "            score = meteor_score.meteor_score([reference_tokens], candidate_tokens)\n",
        "            meteor_scores.append(score)\n",
        "\n",
        "        return max(meteor_scores)\n",
        "\n",
        "    def evaluate_summaries(self,\n",
        "                         chatgpt_summary: str,\n",
        "                         system_summary: str,\n",
        "                         references: List[str]) -> Tuple[pd.DataFrame, Dict]:\n",
        "        \"\"\"\n",
        "        Bewerten Sie beide Zusammenfassungen anhand der ROUGE- und METEOR-Metriken.\n",
        "\n",
        "        Args:\n",
        "            chatgpt_summary: Von ChatGPT erzeugte Zusammenfassung\n",
        "            system_summary: Vom System erzeugte Zusammenfassung\n",
        "            references: Liste der Referenzzusammenfassungen\n",
        "\n",
        "        Rückgabe:\n",
        "            Tupel enthält:\n",
        "            - DataFrame mit detaillierten ROUGE-Bewertungen\n",
        "            - Wörterbuch mit METEOR-Bewertungen\n",
        "        \"\"\"\n",
        "        # Calculate ROUGE scores\n",
        "        chatgpt_rouge = self.calculate_rouge_scores(chatgpt_summary, references)\n",
        "        system_rouge = self.calculate_rouge_scores(system_summary, references)\n",
        "\n",
        "        # Calculate METEOR scores\n",
        "        chatgpt_meteor = self.calculate_meteor_score(chatgpt_summary, references)\n",
        "        system_meteor = self.calculate_meteor_score(system_summary, references)\n",
        "\n",
        "        # Create ROUGE comparison DataFrame\n",
        "        rouge_results = pd.DataFrame({\n",
        "            'Metric': ['ROUGE-1', 'ROUGE-2', 'ROUGE-L'],\n",
        "            'ChatGPT': [\n",
        "                chatgpt_rouge['rouge1'],\n",
        "                chatgpt_rouge['rouge2'],\n",
        "                chatgpt_rouge['rougeL']\n",
        "            ],\n",
        "            'Your System': [\n",
        "                system_rouge['rouge1'],\n",
        "                system_rouge['rouge2'],\n",
        "                system_rouge['rougeL']\n",
        "            ]\n",
        "        })\n",
        "\n",
        "        # Create METEOR results dictionary\n",
        "        meteor_results = {\n",
        "            'ChatGPT METEOR': chatgpt_meteor,\n",
        "            'System METEOR': system_meteor\n",
        "        }\n",
        "\n",
        "        return rouge_results, meteor_results\n",
        "\n",
        "def save_results(rouge_df: pd.DataFrame,\n",
        "                meteor_dict: Dict,\n",
        "                output_file: str = 'evaluation_results.txt'):\n",
        "    \"\"\"\n",
        "    Speichern der Auswertungsergebnisse in einer Datei.\n",
        "\n",
        "    Args:\n",
        "        rouge_df: DataFrame mit ROUGE-Bewertungen\n",
        "        meteor_dict: Wörterbuch mit METEOR-Bewertungen\n",
        "        ausgabe_datei: Pfad zur Ausgabedatei\n",
        "    \"\"\"\n",
        "    with open(output_file, 'w', encoding='utf-8') as f:\n",
        "        f.write(\"=== ROUGE Scores ===\\n\")\n",
        "        f.write(rouge_df.to_string())\n",
        "        f.write(\"\\n\\n=== METEOR Scores ===\\n\")\n",
        "        for system, score in meteor_dict.items():\n",
        "            f.write(f\"{system}: {score:.4f}\\n\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Testfall \"Nur Bild\"\n",
        "if __name__ == \"__main__\":\n",
        "    references = [\n",
        "        \"Ein berührender Moment mütterlicher Freude zeigt sich, als eine Frau ihr lächelndes Baby in die Luft hebt.\",\n",
        "        \"Eine Mutter hebt freudig ihr lachendes Baby in die Luft.\",\n",
        "        \"Das Baby trägt eine weiße Windel und streckt sich spielerisch, während die Mutter es über sich hält und anlächelt\"\n",
        "    ]\n",
        "\n",
        "    chatgpt_summary = \"Eine lächelnde Frau hält ein fröhliches Baby in einer weißen Windel hoch in die Luft.\"\n",
        "    system_summary = \"eine Frau, die ein Baby in die Luft hält.\"\n",
        "\n",
        "    # Initialisiere evaluator\n",
        "    evaluator = SummaryEvaluator()\n",
        "\n",
        "    # Berechne scores\n",
        "    rouge_results, meteor_results = evaluator.evaluate_summaries(\n",
        "        chatgpt_summary,\n",
        "        system_summary,\n",
        "        references\n",
        "    )\n",
        "\n",
        "    # Zeig die Ergebnisse\n",
        "    print(\"\\nROUGE Score Comparison:\")\n",
        "    print(rouge_results.to_string(index=False))\n",
        "    print(\"\\nMETEOR Score Comparison:\")\n",
        "    for system, score in meteor_results.items():\n",
        "        print(f\"{system}: {score:.4f}\")\n",
        "\n",
        "    # Speichere die Ergebnisse in einer Datei\n",
        "    save_results(rouge_results, meteor_results, 'evaluation_nur_Bild.txt')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8upqjdl_djY8",
        "outputId": "537ff774-3bfb-4152-a29d-91365060f539"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "ROUGE Score Comparison:\n",
            " Metric  ChatGPT  Your System\n",
            "ROUGE-1 0.461538     0.500000\n",
            "ROUGE-2 0.222222     0.333333\n",
            "ROUGE-L 0.358974     0.500000\n",
            "\n",
            "METEOR Score Comparison:\n",
            "ChatGPT METEOR: 0.4891\n",
            "System METEOR: 0.5114\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Testfall \"Nur Text\"\n",
        "if __name__ == \"__main__\":\n",
        "    references = [\n",
        "        \"Die Folie beschreibt die zunehmenden Herausforderungen in der Softwaretechnik, wie steigende Komplexität, längere Lebensdauer und wachsende Anforderungen an Anwendungen. Außerdem wird betont, dass die Softwareentwicklung ein zentraler Bestandteil der Systementwicklung ist und die Pflege von Altsystemen immer wichtiger wird.\",\n",
        "        \"Es wird erläutert, warum Softwaretechnik wichtig ist, mit Fokus auf die wachsende Komplexität von Programmen und die zunehmende Bedeutung der Softwareentwicklung. Die Pflege von Altsystemen und die längere Lebensdauer von Software stellen weitere Herausforderungen dar.\",\n",
        "        \"Die Folie thematisiert die Verschärfung von Problemen in der Softwaretechnik, einschließlich zunehmender Komplexität, längerer Lebenszyklen und wachsender Anforderungen. Entwickler widmen sich zunehmend der Pflege bestehender Altsysteme.\"\n",
        "    ]\n",
        "\n",
        "    chatgpt_summary = \"Die Komplexität von Programmen, deren Umfang und Lebensdauer nehmen ständig zu, während neue Anwendungen für den Rechnereinsatz erschlossen werden. Softwareentwicklung ist ein wesentlicher Bestandteil der Systementwicklung, und immer mehr Entwickler sind mit der Pflege von Altsystemen beschäftigt. Dies führt zu einer Verschärfung der Probleme in der Softwareentwicklung.\"\n",
        "    system_summary = \"Komplexität von Programmen nimmt ständig zu Umfang und Lebensdauer nehmen. Neue Anwendungen werden für den Rechnereinsatz erschlossen. Softwareentwicklung ist ein integraler Bestandteil der Systementwickler.\"\n",
        "\n",
        "    evaluator = SummaryEvaluator()\n",
        "\n",
        "    rouge_results, meteor_results = evaluator.evaluate_summaries(\n",
        "        chatgpt_summary,\n",
        "        system_summary,\n",
        "        references\n",
        "    )\n",
        "\n",
        "    print(\"\\nROUGE Score Comparison:\")\n",
        "    print(rouge_results.to_string(index=False))\n",
        "    print(\"\\nMETEOR Score Comparison:\")\n",
        "    for system, score in meteor_results.items():\n",
        "        print(f\"{system}: {score:.4f}\")\n",
        "\n",
        "    save_results(rouge_results, meteor_results, 'evaluation_nur_Text.txt')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E4Iyb42O98pM",
        "outputId": "fb552124-5bea-4ad7-f5ad-48c7fb22ed98"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "ROUGE Score Comparison:\n",
            " Metric  ChatGPT  Your System\n",
            "ROUGE-1 0.416667     0.318841\n",
            "ROUGE-2 0.133333     0.095238\n",
            "ROUGE-L 0.291667     0.231884\n",
            "\n",
            "METEOR Score Comparison:\n",
            "ChatGPT METEOR: 0.3287\n",
            "System METEOR: 0.1744\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Testfall: Bild und Text\n",
        "if __name__ == \"__main__\":\n",
        "    references = [\n",
        "        \"Die Folie erklärt das Wasserfallmodell als ein lineares Entwicklungsmodell, bei dem Produkte wie in einem Wasserfall von einer Phase zur nächsten übergehen. Das Bild eines Wasserfalls verdeutlicht die schrittweise Abfolge, während die Text die Ursprünge und Weiterentwicklungen des Modells erläutert.\",\n",
        "        \"Das Wasserfallmodell wird als erstes umfassendes Modell der Softwaretechnik beschrieben, basierend auf dem stagewise model von Benington (1956). Das Bild eines Wasserfalls symbolisiert die lineare Struktur, bei der jede Phase abgeschlossen sein muss, bevor die nächste beginnt.\",\n",
        "        \"Die Folie stellt das Wasserfallmodell als ein stufenweises Entwicklungsmodell vor, inspiriert vom natürlichen Ablauf eines Wasserfalls, wie im Bild dargestellt. Ursprünge und Weiterentwicklungen durch Benington, Royce und Boehm werden ebenfalls genannt.\"\n",
        "    ]\n",
        "\n",
        "    chatgpt_summary = \"Das Wasserfallmodell beschreibt einen linearen Entwicklungsprozess, bei dem die Ergebnisse einer Phase wie bei einem Wasserfall in die nächste übergehen. Es ist eines der ersten umfassenden Modelle im Software Engineering, basiert auf dem stagewise model von Benington (1956) und wurde durch Royce und Boehm weiterentwickelt. Das Bild eines Wasserfalls verdeutlicht die sequentielle Natur des Prozesses.\"\n",
        "    system_summary = \"HS Bremen, FK4, Softwaretechnik, ISS & ATMECH, WiSe 23/24, Prof. Dr. -Ing. J. Matevska 11 Wasserfallmodell. Basiert auf dem stagewise model von Benington [1956] Weiterentwicklung u. a. durch Royce [1970 & 1987] und Boehm [1981].Das Bild zeigt ein kleiner Wasserfall mitten in einem Wald.\"\n",
        "\n",
        "    evaluator = SummaryEvaluator()\n",
        "\n",
        "    rouge_results, meteor_results = evaluator.evaluate_summaries(\n",
        "        chatgpt_summary,\n",
        "        system_summary,\n",
        "        references\n",
        "    )\n",
        "\n",
        "    print(\"\\nROUGE Score Comparison:\")\n",
        "    print(rouge_results.to_string(index=False))\n",
        "    print(\"\\nMETEOR Score Comparison:\")\n",
        "    for system, score in meteor_results.items():\n",
        "        print(f\"{system}: {score:.4f}\")\n",
        "\n",
        "    save_results(rouge_results, meteor_results, 'evaluation_Bild_und_Text.txt')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Tf4hqIEZNIBw",
        "outputId": "8c4ad98d-8d8d-429a-a767-7cc9d539df2a"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "ROUGE Score Comparison:\n",
            " Metric  ChatGPT  Your System\n",
            "ROUGE-1 0.495050     0.317073\n",
            "ROUGE-2 0.260870     0.175000\n",
            "ROUGE-L 0.319149     0.292683\n",
            "\n",
            "METEOR Score Comparison:\n",
            "ChatGPT METEOR: 0.5322\n",
            "System METEOR: 0.3079\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Testfall: komplexe Bilder\n",
        "if __name__ == \"__main__\":\n",
        "    references = [\n",
        "        \"Während Änderungen in der Anforderungsdefinition kostengünstig sind (1x), steigen sie in der Entwicklung (1,5-6x) und explodieren in der Wartung (60-100x).\",\n",
        "        \"Eine gründliche Anforderungsanalyse minimiert Kostensteigerungen. Änderungen sind in der frühen Phase kostengünstig (1x), aber während der Wartung können sie bis zu 100-mal teurer werden\",\n",
        "        \"Anforderungen frühzeitig zu definieren, ist essenziell, da die Kosten für Änderungen im Entwicklungsprozess exponentiell steigen. Während sie in der Anforderungsdefinition minimal sind, steigen sie in der Entwicklung um das 1,5- bis 6-fache und in der Wartung um das 60- bis 100-fache\"\n",
        "    ]\n",
        "\n",
        "    chatgpt_summary = \"Die Folie zeigt, warum Anforderungs-Engineering wichtig ist, anhand der steigenden Kosten von Änderungen im Entwicklungsprozess. Änderungen während der Anforderungsdefinition kosten am wenigsten (1x), während sie in der Entwicklung (1,5–6x) und besonders in der Wartung (60–100x) exponentiell teurer werden.\"\n",
        "    system_summary = \"HS Bremen, FK4, TI, Softwaretechnik 2, SoSe 2023, Prof. -Ing. J. Matevska 16 Warum ist Anforderungs-Engineering notwendig.Das Bild zeigt ein Balkendiagramm, das den Prozentsatz der Anzahl der diagnostizierten Personen zeigt.\"\n",
        "\n",
        "    evaluator = SummaryEvaluator()\n",
        "\n",
        "    rouge_results, meteor_results = evaluator.evaluate_summaries(\n",
        "        chatgpt_summary,\n",
        "        system_summary,\n",
        "        references\n",
        "    )\n",
        "\n",
        "    print(\"\\nROUGE Score Comparison:\")\n",
        "    print(rouge_results.to_string(index=False))\n",
        "    print(\"\\nMETEOR Score Comparison:\")\n",
        "    for system, score in meteor_results.items():\n",
        "        print(f\"{system}: {score:.4f}\")\n",
        "\n",
        "    save_results(rouge_results, meteor_results, 'evaluation_komplexe_Bilder.txt')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NkmKLyLDQc_h",
        "outputId": "a4d291ee-eb1b-44ad-e733-9ab1c895a4a7"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "ROUGE Score Comparison:\n",
            " Metric  ChatGPT  Your System\n",
            "ROUGE-1 0.550725     0.126582\n",
            "ROUGE-2 0.388060     0.000000\n",
            "ROUGE-L 0.521739     0.096774\n",
            "\n",
            "METEOR Score Comparison:\n",
            "ChatGPT METEOR: 0.6702\n",
            "System METEOR: 0.0903\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Testfall: Folie mit mathematischen Formeln\n",
        "if __name__ == \"__main__\":\n",
        "    references = [\"Der magnetische Fluss folgt einer sinusförmigen Funktion, die durch Φ=Φmaxcos(𝜔𝑡) beschrieben wird. Laut Induktionsgesetz induziert eine rotierende Spule in einem Magnetfeld eine sinusförmige Wechselspannung 𝑢(𝑡)=ûsin(𝜔𝑡), wobei û=𝑁𝜔Φmax. Die Frequenz f ist der Kehrwert der Periodendauer T, und die Kreisfrequenz ω ist 2𝜋𝑓.\",\n",
        "        \"Eine Spule, die in einem homogenen Magnetfeld gedreht wird, erzeugt eine sinusförmige Wechselspannung. Der Zusammenhang zwischen Frequenz (f), Periodendauer (T) und Kreisfrequenz (ω) wird durch 𝜔=2𝜋𝑓 und 𝑇=1/𝑓 beschrieben. Der magnetische Fluss verändert sich sinusförmig mit der Zeit.\",\n",
        "        \"Der magnetische Fluss Φ und die induzierte Spannung 𝑢(𝑡)sind zeitabhängig und folgen sinusförmigen Gesetzmäßigkeiten. Die Kreisfrequenz ω und die Frequenz f beschreiben die zeitliche Veränderung der Spannung, wobei 𝑇=1/f die Periodendauer angibt. Die Induktion basiert auf der Rotation der Spule im Magnetfeld.\"\n",
        "    ]\n",
        "    chatgpt_summary = \"Die Folie erklärt, dass der magnetische Fluss in einer Spule eine sinusförmige Spannung induziert, wenn die Spule in einem homogenen Magnetfeld rotiert. Die Spannung hängt von der Windungszahl N, der Winkelgeschwindigkeit ω, und der maximalen Flussdichte Φmax ab, mit einer Periodendauer T, die in Sekunden gemessen wird.\"\n",
        "    system_summary = \"Für den magnetischen Fluss ergibt sich somit Φmax cosω. Die Zeit für einen vollen Umlauf wird Periodendauer genannt. Die Einheit ist die Sekunde.\"\n",
        "\n",
        "    evaluator = SummaryEvaluator()\n",
        "\n",
        "    rouge_results, meteor_results = evaluator.evaluate_summaries(\n",
        "        chatgpt_summary,\n",
        "        system_summary,\n",
        "        references\n",
        "    )\n",
        "\n",
        "    print(\"\\nROUGE Score Comparison:\")\n",
        "    print(rouge_results.to_string(index=False))\n",
        "    print(\"\\nMETEOR Score Comparison:\")\n",
        "    for system, score in meteor_results.items():\n",
        "        print(f\"{system}: {score:.4f}\")\n",
        "\n",
        "    save_results(rouge_results, meteor_results, 'evaluation_Folie_mit_mathFormeln.txt')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WkJX1Zlt90j4",
        "outputId": "8d686142-b836-439e-954d-96427eca052d"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "ROUGE Score Comparison:\n",
            " Metric  ChatGPT  Your System\n",
            "ROUGE-1 0.478261     0.264706\n",
            "ROUGE-2 0.206897     0.000000\n",
            "ROUGE-L 0.347826     0.205882\n",
            "\n",
            "METEOR Score Comparison:\n",
            "ChatGPT METEOR: 0.3573\n",
            "System METEOR: 0.1160\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n"
          ]
        }
      ]
    }
  ]
}